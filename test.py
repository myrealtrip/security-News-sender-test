import os
import json
import time
import re
import requests
import feedparser
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ (ìˆëŠ” ê²½ìš°)
load_dotenv()

# âœ… HTTPS ì‚¬ìš© ê¶Œì¥
RSS_URLS = [
    "https://www.boannews.com/media/news_rss.xml?mkind=1",
    "https://www.boannews.com/media/news_rss.xml?mkind=2",
    "https://www.boannews.com/media/news_rss.xml?mkind=4",
    "https://www.boannews.com/media/news_rss.xml?mkind=5",
    "https://www.boannews.com/media/news_rss.xml",
    "https://www.boannews.com/media/news_rss.xml?skind=5",
    "https://www.boannews.com/media/news_rss.xml?skind=7",
    "https://www.boannews.com/media/news_rss.xml?skind=3",
    "https://www.boannews.com/media/news_rss.xml?skind=2",
    "https://www.boannews.com/media/news_rss.xml?skind=6",
]

STATE_FILE = "state.test.json"  # âœ… í…ŒìŠ¤íŠ¸ìš© ìƒíƒœ íŒŒì¼
SLACK_WEBHOOK = os.environ.get("SLACK_WEBHOOK_URL", "")
if not SLACK_WEBHOOK:
    print("âš ï¸  ê²½ê³ : SLACK_WEBHOOK_URL í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    print("   .env íŒŒì¼ì„ ìƒì„±í•˜ê±°ë‚˜ í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
    print("   í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹œì—ëŠ” ìŠ¬ë™ ë°œì†¡ì´ ê±´ë„ˆëœë‹ˆë‹¤.")

# AI API ì„¤ì • (ì„ íƒì‚¬í•­)
# ì‚¬ìš© ì•ˆ í•˜ë ¤ë©´: USE_AI_JUDGMENT = False
USE_AI_JUDGMENT = os.environ.get("USE_AI_JUDGMENT", "false").lower() == "true"
AI_PROVIDER = os.environ.get("AI_PROVIDER", "openai").lower()  # "openai" or "anthropic"

# OpenAI ì„¤ì •
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY", "")
OPENAI_MODEL = os.environ.get("OPENAI_MODEL", "gpt-4o-mini")  # ë˜ëŠ” "gpt-4", "gpt-3.5-turbo"

# Anthropic (Claude) ì„¤ì •
ANTHROPIC_API_KEY = os.environ.get("ANTHROPIC_API_KEY", "")
ANTHROPIC_MODEL = os.environ.get("ANTHROPIC_MODEL", "claude-3-5-sonnet-20241022")  # ë˜ëŠ” "claude-3-opus-20240229"

# í•„í„°ë§ í‚¤ì›Œë“œ (ì œëª©ì´ë‚˜ ë‚´ìš©ì— í¬í•¨ë˜ì–´ì•¼ í•¨)
FILTER_KEYWORDS = []  # ì˜ˆ: ["í•´í‚¹", "ë³´ì•ˆ", "ì·¨ì•½ì "] - ë¹ˆ ë¦¬ìŠ¤íŠ¸ë©´ í•„í„°ë§ ì•ˆ í•¨

# ëª¨ë‹ˆí„°ë§ ì„¤ì •
CHECK_INTERVAL = int(os.environ.get("CHECK_INTERVAL", "300"))  # ê¸°ë³¸ 5ë¶„ (ì´ˆ ë‹¨ìœ„)
DAEMON_MODE = os.environ.get("DAEMON_MODE", "false").lower() == "true"  # ë°ëª¬ ëª¨ë“œë¡œ ì‹¤í–‰

# AI íŒë‹¨ ê¸°ì¤€ í”„ë¡¬í”„íŠ¸ íŒŒì¼ ê²½ë¡œ
AI_PROMPT_FILE = os.environ.get("AI_PROMPT_FILE", "ai_prompt.txt")

def load_ai_prompt():
    """AI íŒë‹¨ í”„ë¡¬í”„íŠ¸ íŒŒì¼ì„ ì½ì–´ì˜´"""
    prompt_file = AI_PROMPT_FILE
    if os.path.exists(prompt_file):
        with open(prompt_file, "r", encoding="utf-8") as f:
            return f.read().strip()
    else:
        # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ (íŒŒì¼ì´ ì—†ì„ ê²½ìš°)
        return """ì´ ë³´ì•ˆ ë‰´ìŠ¤ ê¸°ì‚¬ê°€ ë‹¤ìŒ ê¸°ì¤€ì— ë¶€í•©í•˜ëŠ”ì§€ íŒë‹¨í•´ì£¼ì„¸ìš”:

1. ì¤‘ìš”ë„: ë†’ìŒ/ë³´í†µ/ë‚®ìŒ
2. ê¸´ê¸‰ë„: ê¸´ê¸‰/ë³´í†µ/ë‚®ìŒ
3. ìš°ë¦¬ íšŒì‚¬/ì„œë¹„ìŠ¤ì— ì˜í–¥ì„ ì¤„ ê°€ëŠ¥ì„±: ë†’ìŒ/ë³´í†µ/ë‚®ìŒ
4. ìš”ì•½: ê¸°ì‚¬ì˜ í•µì‹¬ ë‚´ìš©ì„ 3-5ë¬¸ì¥ìœ¼ë¡œ ìƒì„¸íˆ ìš”ì•½ (ì£¼ìš” ë‚´ìš©, ë°°ê²½, ì˜í–¥ ë“±ì„ í¬í•¨)
5. ê¶Œì¥ ì¡°ì¹˜: í•„ìš”í•œ ê²½ìš° ê¶Œì¥ ì¡°ì¹˜ì‚¬í•­

ì¤‘ìš”ë„ê°€ "ë‚®ìŒ"ì´ê³  ì˜í–¥ ê°€ëŠ¥ì„±ì´ "ë‚®ìŒ"ì¸ ê²½ìš°ëŠ” ìš°ë¦¬ì—ê²Œ í•„ìš”í•˜ì§€ ì•Šì€ ì •ë³´ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{
  "importance": "ë†’ìŒ|ë³´í†µ|ë‚®ìŒ",
  "urgency": "ê¸´ê¸‰|ë³´í†µ|ë‚®ìŒ",
  "impact_risk": "ë†’ìŒ|ë³´í†µ|ë‚®ìŒ",
  "is_relevant": true|false,
  "summary": "ìƒì„¸í•œ ìš”ì•½ ë‚´ìš© (3-5ë¬¸ì¥)",
  "key_points": ["í•µì‹¬ í¬ì¸íŠ¸ 1", "í•µì‹¬ í¬ì¸íŠ¸ 2", "í•µì‹¬ í¬ì¸íŠ¸ 3"],
  "recommended_action": "ê¶Œì¥ ì¡°ì¹˜ì‚¬í•­ ë˜ëŠ” ì—†ìŒ"
}"""

# AI íŒë‹¨ ê¸°ì¤€ í”„ë¡¬í”„íŠ¸ (íŒŒì¼ì—ì„œ ë¡œë“œ)
AI_JUDGMENT_PROMPT = load_ai_prompt()

# AI íŒë‹¨ í•„í„°ë§ ê¸°ì¤€ (ì´ ê¸°ì¤€ì„ ë§Œì¡±í•˜ëŠ” ê²ƒë§Œ ìŠ¬ë™ ë°œì†¡)
AI_FILTER_REQUIRE_RELEVANT = os.environ.get("AI_FILTER_REQUIRE_RELEVANT", "false").lower() == "true"  # is_relevantê°€ trueì¸ ê²ƒë§Œ
AI_FILTER_MIN_IMPORTANCE = os.environ.get("AI_FILTER_MIN_IMPORTANCE", "ë‚®ìŒ")  # ìµœì†Œ ì¤‘ìš”ë„ (ë‚®ìŒ/ë³´í†µ/ë†’ìŒ)
AI_FILTER_MIN_IMPACT = os.environ.get("AI_FILTER_MIN_IMPACT", "ë‚®ìŒ")  # ìµœì†Œ ì˜í–¥ë„ (ë‚®ìŒ/ë³´í†µ/ë†’ìŒ)

HEADERS = {
    "User-Agent": "MyrealtripSecurityBot/1.0"
}

# -----------------------------
# ìƒíƒœ ê´€ë¦¬
# -----------------------------
def load_state():
    if not os.path.exists(STATE_FILE):
        return {"seen": []}
    with open(STATE_FILE, "r", encoding="utf-8") as f:
        return json.load(f)

def save_state(state):
    with open(STATE_FILE, "w", encoding="utf-8") as f:
        json.dump(state, f, ensure_ascii=False, indent=2)

# -----------------------------
# RSS ìœ í‹¸
# -----------------------------
def entry_uid(e):
    return (
        getattr(e, "id", None)
        or getattr(e, "guid", None)
        or getattr(e, "link", None)
        or e.get("title")
    )

def entry_ts(e):
    t = getattr(e, "published_parsed", None) or getattr(e, "updated_parsed", None)
    if t:
        return int(time.mktime(t))
    return 0

def matches_filter(e):
    """í•­ëª©ì´ í•„í„° í‚¤ì›Œë“œì™€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸"""
    if not FILTER_KEYWORDS:
        return True  # í•„í„°ê°€ ì—†ìœ¼ë©´ ëª¨ë‘ í†µê³¼
    
    title = e.get("title", "").lower()
    summary = e.get("summary", "").lower()
    content = title + " " + summary
    
    # í•˜ë‚˜ë¼ë„ í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ True
    return any(keyword.lower() in content for keyword in FILTER_KEYWORDS)

def fetch_latest_entry(url: str):
    try:
        r = requests.get(url, headers=HEADERS, timeout=10)
        r.raise_for_status()

        feed = feedparser.parse(r.text)

        # â— bozoì—¬ë„ entriesê°€ ìˆìœ¼ë©´ ì‚¬ìš©
        if not feed.entries:
            if feed.bozo:
                print("[WARN] BOZO but no entries:", url, feed.bozo_exception)
            return None

        # í•„í„°ë§ ì ìš©
        filtered_entries = [e for e in feed.entries if matches_filter(e)]
        if not filtered_entries:
            return None

        entries = sorted(filtered_entries, key=entry_ts, reverse=True)
        return entries[0]

    except Exception as e:
        print("[ERROR] fetch failed:", url, e)
        return None

def pick_global_latest():
    candidates = []

    for url in RSS_URLS:
        e = fetch_latest_entry(url)
        if e:
            candidates.append(e)

    if not candidates:
        return None

    candidates.sort(key=entry_ts, reverse=True)
    return candidates[0]

def fetch_all_recent_entries(max_entries=10):
    """ëª¨ë“  RSS í”¼ë“œì—ì„œ ìµœê·¼ ê¸°ì‚¬ë“¤ì„ ê°€ì ¸ì˜´"""
    all_entries = []
    
    for url in RSS_URLS:
        try:
            r = requests.get(url, headers=HEADERS, timeout=10)
            r.raise_for_status()
            
            feed = feedparser.parse(r.text)
            
            if not feed.entries:
                continue
            
            # í•„í„°ë§ ì ìš©
            filtered_entries = [e for e in feed.entries if matches_filter(e)]
            all_entries.extend(filtered_entries)
            
        except Exception as e:
            print(f"[ERROR] fetch failed: {url}, {e}")
            continue
    
    # ì¤‘ë³µ ì œê±° (UID ê¸°ì¤€)
    seen_uids = set()
    unique_entries = []
    for e in all_entries:
        uid = entry_uid(e)
        if uid and uid not in seen_uids:
            seen_uids.add(uid)
            unique_entries.append(e)
    
    # ì‹œê°„ìˆœ ì •ë ¬
    unique_entries.sort(key=entry_ts, reverse=True)
    
    return unique_entries[:max_entries]

# -----------------------------
# AI í”„ë¡¬í”„íŠ¸ ìƒì„±
# -----------------------------
def create_ai_prompt(e, task_description=None):
    """
    ê¸°ì‚¬ ì •ë³´ë¥¼ AIê°€ íŒë‹¨í•  ìˆ˜ ìˆëŠ” í”„ë¡¬í”„íŠ¸ë¡œ ë³€í™˜
    
    Args:
        e: RSS entry ê°ì²´
        task_description: AIì—ê²Œ ìš”ì²­í•  ì‘ì—… ì„¤ëª… (ì˜ˆ: "ì´ ê¸°ì‚¬ê°€ ë³´ì•ˆ ê´€ë ¨ ì¤‘ìš”í•œ ë‰´ìŠ¤ì¸ì§€ íŒë‹¨í•´ì£¼ì„¸ìš”")
    
    Returns:
        str: AI í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´
    """
    title = e.get("title", "(ì œëª© ì—†ìŒ)")
    link = e.get("link", "")
    summary = e.get("summary", e.get("description", ""))
    published = e.get("published", e.get("updated", ""))
    author = e.get("author", "")
    
    # íƒœê·¸ ì •ë³´ ìˆ˜ì§‘
    tags = []
    if hasattr(e, "tags") and e.tags:
        tags = [tag.get("term", "") for tag in e.tags if tag.get("term")]
    
    prompt = f"""ë‹¤ìŒì€ ë³´ì•ˆ ë‰´ìŠ¤ ê¸°ì‚¬ ì •ë³´ì…ë‹ˆë‹¤:

ì œëª©: {title}
ë§í¬: {link}
ë°œí–‰ì¼: {published}
ì‘ì„±ì: {author if author else "(ì •ë³´ ì—†ìŒ)"}
íƒœê·¸: {', '.join(tags) if tags else "(íƒœê·¸ ì—†ìŒ)"}

ê¸°ì‚¬ ìš”ì•½/ë‚´ìš©:
{summary}

---
"""
    
    if task_description:
        prompt += f"\nì‘ì—… ìš”ì²­: {task_description}\n"
    else:
        prompt += "\nìœ„ ê¸°ì‚¬ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”.\n"
    
    return prompt

def create_ai_prompt_json(e, task_description=None):
    """
    ê¸°ì‚¬ ì •ë³´ë¥¼ JSON í˜•íƒœë¡œ êµ¬ì¡°í™”í•˜ì—¬ ë°˜í™˜ (API í˜¸ì¶œìš©)
    
    Args:
        e: RSS entry ê°ì²´
        task_description: AIì—ê²Œ ìš”ì²­í•  ì‘ì—… ì„¤ëª…
    
    Returns:
        dict: êµ¬ì¡°í™”ëœ ê¸°ì‚¬ ì •ë³´
    """
    title = e.get("title", "(ì œëª© ì—†ìŒ)")
    link = e.get("link", "")
    summary = e.get("summary", e.get("description", ""))
    published = e.get("published", e.get("updated", ""))
    author = e.get("author", "")
    
    # íƒœê·¸ ì •ë³´ ìˆ˜ì§‘
    tags = []
    if hasattr(e, "tags") and e.tags:
        tags = [tag.get("term", "") for tag in e.tags if tag.get("term")]
    
    data = {
        "title": title,
        "link": link,
        "summary": summary,
        "published": published,
        "author": author if author else None,
        "tags": tags if tags else [],
        "task_description": task_description
    }
    
    return data

# -----------------------------
# AI íŒë‹¨
# -----------------------------
def judge_with_ai(e, custom_prompt=None):
    """
    AIë¥¼ ì‚¬ìš©í•˜ì—¬ ê¸°ì‚¬ë¥¼ íŒë‹¨
    ì‹ ê·œ ê¸°ì‚¬ì— ëŒ€í•´ì„œë§Œ í˜¸ì¶œë¨ (ë¹„ìš© ì ˆê°)
    
    Args:
        e: RSS entry ê°ì²´
        custom_prompt: ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ (ì—†ìœ¼ë©´ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©)
    
    Returns:
        dict: AI íŒë‹¨ ê²°ê³¼ ë˜ëŠ” None (ì‹¤íŒ¨ ì‹œ)
    """
    if not USE_AI_JUDGMENT:
        return None
    
    # API í‚¤ í™•ì¸
    if AI_PROVIDER == "anthropic":
        if not ANTHROPIC_API_KEY:
            print("[WARN] ANTHROPIC_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None
    else:  # openai
        if not OPENAI_API_KEY:
            print("[WARN] OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None
    
    try:
        prompt = create_ai_prompt(e, custom_prompt or AI_JUDGMENT_PROMPT)
        
        # Anthropic (Claude) API í˜¸ì¶œ
        if AI_PROVIDER == "anthropic":
            headers = {
                "x-api-key": ANTHROPIC_API_KEY,
                "anthropic-version": "2023-06-01",
                "Content-Type": "application/json"
            }
            
            payload = {
                "model": ANTHROPIC_MODEL,
                "max_tokens": 4096,
                "system": "ë‹¹ì‹ ì€ ë³´ì•ˆ ë‰´ìŠ¤ë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ê¸°ì‚¬ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ê°ê´€ì ìœ¼ë¡œ íŒë‹¨í•´ì£¼ì„¸ìš”.",
                "messages": [
                    {
                        "role": "user",
                        "content": prompt
                    }
                ]
            }
            
            response = requests.post(
                "https://api.anthropic.com/v1/messages",
                headers=headers,
                json=payload,
                timeout=60
            )
            response.raise_for_status()
            
            result = response.json()
            ai_response = result["content"][0]["text"]
        
        # OpenAI API í˜¸ì¶œ
        else:
            headers = {
                "Authorization": f"Bearer {OPENAI_API_KEY}",
                "Content-Type": "application/json"
            }
            
            payload = {
                "model": OPENAI_MODEL,
                "messages": [
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ ë³´ì•ˆ ë‰´ìŠ¤ë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ê¸°ì‚¬ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ê°ê´€ì ìœ¼ë¡œ íŒë‹¨í•´ì£¼ì„¸ìš”."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                "temperature": 0.3,
                "max_tokens": 1000
            }
            
            response = requests.post(
                "https://api.openai.com/v1/chat/completions",
                headers=headers,
                json=payload,
                timeout=30
            )
            response.raise_for_status()
            
            result = response.json()
            ai_response = result["choices"][0]["message"]["content"]
        
        # JSON íŒŒì‹± ì‹œë„
        try:
            # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°
            cleaned_response = re.sub(r'```json\s*', '', ai_response)
            cleaned_response = re.sub(r'```\s*', '', cleaned_response)
            cleaned_response = cleaned_response.strip()
            
            # JSON ê°ì²´ ì°¾ê¸° (ì¤‘ì²©ëœ ì¤‘ê´„í˜¸ë„ ì²˜ë¦¬)
            brace_count = 0
            start_idx = -1
            for i, char in enumerate(cleaned_response):
                if char == '{':
                    if start_idx == -1:
                        start_idx = i
                    brace_count += 1
                elif char == '}':
                    brace_count -= 1
                    if brace_count == 0 and start_idx != -1:
                        json_str = cleaned_response[start_idx:i+1]
                        judgment = json.loads(json_str)
                        break
            else:
                # JSONì„ ì°¾ì§€ ëª»í•œ ê²½ìš° ì›ë³¸ ì‘ë‹µ ë°˜í™˜
                judgment = {"raw_response": ai_response}
        except (json.JSONDecodeError, ValueError) as e:
            print(f"[WARN] JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            judgment = {"raw_response": ai_response}
        
        return judgment
        
    except Exception as e:
        print(f"[ERROR] AI judgment failed: {e}")
        return None

def should_send_article(ai_judgment):
    """AI íŒë‹¨ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìŠ¬ë™ ë°œì†¡ ì—¬ë¶€ ê²°ì •"""
    if not ai_judgment:
        return True  # AI íŒë‹¨ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ì ìœ¼ë¡œ ë°œì†¡
    
    # is_relevant ì²´í¬
    if AI_FILTER_REQUIRE_RELEVANT:
        if ai_judgment.get("is_relevant") == False:
            return False
    
    # ì¤‘ìš”ë„ ì²´í¬
    importance_levels = {"ë‚®ìŒ": 1, "ë³´í†µ": 2, "ë†’ìŒ": 3}
    min_importance = importance_levels.get(AI_FILTER_MIN_IMPORTANCE, 1)
    article_importance = importance_levels.get(ai_judgment.get("importance", "ë‚®ìŒ"), 1)
    if article_importance < min_importance:
        return False
    
    # ì˜í–¥ë„ ì²´í¬
    min_impact = importance_levels.get(AI_FILTER_MIN_IMPACT, 1)
    article_impact = importance_levels.get(ai_judgment.get("impact_risk", "ë‚®ìŒ"), 1)
    if article_impact < min_impact:
        return False
    
    return True

# -----------------------------
# Slack ë°œì†¡
# -----------------------------
def post_one_to_slack(e, ai_judgment=None):
    if not SLACK_WEBHOOK:
        print("âš ï¸  SLACK_WEBHOOK_URLì´ ì„¤ì •ë˜ì§€ ì•Šì•„ ìŠ¬ë™ ë°œì†¡ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        print(f"   ê¸°ì‚¬: {e.get('title', '')[:50]}...")
        return
    
    title = e.get("title", "(no title)")
    link = e.get("link", "")
    published = e.get("published", e.get("updated", ""))

    blocks = [
        {
            "type": "header",
            "text": {"type": "plain_text", "text": "ğŸ”” ë³´ì•ˆë‰´ìŠ¤ ì•Œë¦¼"}
        },
        {
            "type": "section",
            "text": {"type": "mrkdwn", "text": f"*<{link}|{title}>*\nğŸ“… {published}"}
        },
    ]
    
    # AI íŒë‹¨ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì¶”ê°€
    if ai_judgment:
        judgment_text = "*ğŸ¤– AI ë¶„ì„ ê²°ê³¼*\n"
        
        if "importance" in ai_judgment:
            importance_emoji = {"ë†’ìŒ": "ğŸ”´", "ë³´í†µ": "ğŸŸ¡", "ë‚®ìŒ": "ğŸŸ¢"}.get(ai_judgment["importance"], "âšª")
            urgency_emoji = {"ê¸´ê¸‰": "ğŸš¨", "ë³´í†µ": "ğŸŸ¡", "ë‚®ìŒ": "ğŸŸ¢"}.get(ai_judgment.get("urgency", ""), "âšª")
            relevance_emoji = "âœ…" if ai_judgment.get("is_relevant", True) else "âŒ"
            
            judgment_text += f"{importance_emoji} *ì¤‘ìš”ë„:* {ai_judgment.get('importance', 'N/A')}\n"
            judgment_text += f"{urgency_emoji} *ê¸´ê¸‰ë„:* {ai_judgment.get('urgency', 'N/A')}\n"
            judgment_text += f"ğŸ“Š *ì˜í–¥ ê°€ëŠ¥ì„±:* {ai_judgment.get('impact_risk', 'N/A')}\n"
            judgment_text += f"{relevance_emoji} *ê´€ë ¨ì„±:* {'ê´€ë ¨ ìˆìŒ' if ai_judgment.get('is_relevant', True) else 'ê´€ë ¨ ì—†ìŒ'}\n"
            
            # ìƒì„¸ ìš”ì•½
            if ai_judgment.get("summary"):
                blocks.append({
                    "type": "section",
                    "text": {"type": "mrkdwn", "text": judgment_text}
                })
                blocks.append({
                    "type": "divider"
                })
                blocks.append({
                    "type": "section",
                    "text": {"type": "mrkdwn", "text": f"*ğŸ“ ê¸°ì‚¬ ìš”ì•½*\n{ai_judgment['summary']}"}
                })
            else:
                blocks.append({
                    "type": "section",
                    "text": {"type": "mrkdwn", "text": judgment_text}
                })
            
            # í•µì‹¬ í¬ì¸íŠ¸
            if ai_judgment.get("key_points") and isinstance(ai_judgment["key_points"], list):
                key_points_text = "\n".join([f"â€¢ {point}" for point in ai_judgment["key_points"]])
                blocks.append({
                    "type": "section",
                    "text": {"type": "mrkdwn", "text": f"*ğŸ”‘ í•µì‹¬ í¬ì¸íŠ¸*\n{key_points_text}"}
                })
            
            # ê¶Œì¥ ì¡°ì¹˜
            if ai_judgment.get("recommended_action") and ai_judgment["recommended_action"] != "ì—†ìŒ":
                blocks.append({
                    "type": "section",
                    "text": {"type": "mrkdwn", "text": f"*ğŸ’¡ ê¶Œì¥ ì¡°ì¹˜*\n{ai_judgment['recommended_action']}"}
                })
        else:
            # JSON íŒŒì‹± ì‹¤íŒ¨í•œ ê²½ìš° ì›ë³¸ ì‘ë‹µ í‘œì‹œ
            blocks.append({
                "type": "section",
                "text": {"type": "mrkdwn", "text": f"*ğŸ¤– AI ë¶„ì„*\n{ai_judgment.get('raw_response', 'ë¶„ì„ ì™„ë£Œ')}"}
            })

    resp = requests.post(
        SLACK_WEBHOOK,
        json={"blocks": blocks},
        timeout=10,
    )
    resp.raise_for_status()

# -----------------------------
# main
# -----------------------------
def process_articles():
    """
    ê¸°ì‚¬ë“¤ì„ ì²˜ë¦¬í•˜ê³  ìŠ¬ë™ì— ë°œì†¡
    âš ï¸ ì¤‘ìš”: ì‹ ê·œ ê¸°ì‚¬ê°€ ìˆì„ ë•Œë§Œ AI API í˜¸ì¶œ (ë¹„ìš© ì ˆê°)
    """
    state = load_state()
    seen = set(state.get("seen", []))

    # ìµœê·¼ ê¸°ì‚¬ë“¤ ê°€ì ¸ì˜¤ê¸° (ì—¬ëŸ¬ ê°œ)
    recent_entries = fetch_all_recent_entries(max_entries=20)
    
    if not recent_entries:
        print("âŒ No RSS entries found.")
        return 0

    # ì‹ ê·œ ê¸°ì‚¬ë§Œ í•„í„°ë§ (ì´ë¯¸ ë³¸ ê¸°ì‚¬ëŠ” ì œì™¸)
    new_entries = []
    for entry in recent_entries:
        uid = entry_uid(entry)
        if uid and uid not in seen:
            new_entries.append(entry)
    
    if not new_entries:
        print("â„¹ï¸ ìƒˆë¡œìš´ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤. (AI API í˜¸ì¶œ ì—†ìŒ)")
        return 0
    
    print(f"ğŸ“° ì‹ ê·œ ê¸°ì‚¬ {len(new_entries)}ê±´ ë°œê²¬ â†’ AI íŒë‹¨ ì‹œì‘")
    sent_count = 0
    ai_call_count = 0
    
    # ì‹œê°„ìˆœìœ¼ë¡œ ì •ë ¬ëœ ì‹ ê·œ ê¸°ì‚¬ë“¤ë§Œ ì²˜ë¦¬
    for entry in new_entries:
        uid = entry_uid(entry)
        if not uid:
            continue
        
        # AI íŒë‹¨ (ì‹ ê·œ ê¸°ì‚¬ì— ëŒ€í•´ì„œë§Œ í˜¸ì¶œ - ë¹„ìš© ì ˆê°)
        ai_judgment = None
        if USE_AI_JUDGMENT:
            ai_call_count += 1
            print(f"ğŸ¤– AI íŒë‹¨ ì¤‘ ({ai_call_count}/{len(new_entries)}): {entry.get('title', '')[:50]}...")
            ai_judgment = judge_with_ai(entry)
            if ai_judgment:
                print("âœ… AI íŒë‹¨ ì™„ë£Œ")
                
                # AI í•„í„°ë§ ì ìš©
                if not should_send_article(ai_judgment):
                    print(f"â­ï¸ í•„í„°ë§ë¨ (ì¤‘ìš”ë„/ì˜í–¥ë„ ë¶€ì¡±): {entry.get('title', '')[:50]}...")
                    # í•„í„°ë§ëœ ê¸°ì‚¬ë„ seenì— ì¶”ê°€í•´ì„œ ë‹¤ì‹œ ì²´í¬ ì•ˆ í•˜ë„ë¡
                    seen.add(uid)
                    continue
            else:
                print("âš ï¸ AI íŒë‹¨ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰)")
        
        # ìŠ¬ë™ ë°œì†¡
        try:
            post_one_to_slack(entry, ai_judgment)
            seen.add(uid)
            sent_count += 1
            print(f"âœ… ë°œì†¡ ì™„ë£Œ: {entry.get('title', '')[:50]}...")
        except Exception as e:
            print(f"âŒ ìŠ¬ë™ ë°œì†¡ ì‹¤íŒ¨: {e}")
            continue
    
    if USE_AI_JUDGMENT and ai_call_count > 0:
        print(f"ğŸ’° AI API í˜¸ì¶œ: {ai_call_count}ê±´ (ì‹ ê·œ ê¸°ì‚¬ë§Œ)")
    
    # ìƒíƒœ ì €ì¥
    state["seen"] = list(seen)[-2000:]
    save_state(state)
    
    return sent_count

def main():
    if DAEMON_MODE:
        print(f"ğŸ”„ ë°ëª¬ ëª¨ë“œ ì‹œì‘ (ì²´í¬ ê°„ê²©: {CHECK_INTERVAL}ì´ˆ)")
        print("ì¢…ë£Œí•˜ë ¤ë©´ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”.\n")
        
        try:
            while True:
                print(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] RSS ì²´í¬ ì‹œì‘...")
                sent_count = process_articles()
                
                if sent_count > 0:
                    print(f"âœ… {sent_count}ê±´ì˜ ê¸°ì‚¬ë¥¼ ë°œì†¡í–ˆìŠµë‹ˆë‹¤.\n")
                else:
                    print("â„¹ï¸ ìƒˆë¡œìš´ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.\n")
                
                print(f"â³ {CHECK_INTERVAL}ì´ˆ ëŒ€ê¸° ì¤‘...\n")
                time.sleep(CHECK_INTERVAL)
                
        except KeyboardInterrupt:
            print("\nğŸ‘‹ ë°ëª¬ ëª¨ë“œ ì¢…ë£Œ")
    else:
        # í•œ ë²ˆë§Œ ì‹¤í–‰
        print("ğŸ” RSS ì²´í¬ ì‹œì‘...")
        sent_count = process_articles()
        
        if sent_count > 0:
            print(f"âœ… {sent_count}ê±´ì˜ ê¸°ì‚¬ë¥¼ ë°œì†¡í–ˆìŠµë‹ˆë‹¤.")
        else:
            print("â„¹ï¸ ìƒˆë¡œìš´ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()

